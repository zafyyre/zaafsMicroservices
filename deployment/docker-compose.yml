version: '3.3'
services:
  zookeeper:
    image: wurstmeister/zookeeper
    ports:
    - "2181"
    hostname: zookeeper
    container_name: "zookeeper"
    # Mapping the volume from the host to the container for Zookeeper data persistence
    volumes:
      - /home/acit3855zaaf/zookeeper/data:/opt/zookeeper-3.4.13/data

  kafka:
    image: wurstmeister/kafka
    command: [start-kafka.sh]
    ports:
      - 9092:9092
    hostname: kafka
    container_name: kafka
    environment:
      KAFKA_CREATE_TOPICS: "events:1:1" # topic:partition:replicas
      KAFKA_ADVERTISED_HOST_NAME: kafka # docker-machine ip
      KAFKA_LISTENERS: INSIDE://:29092,OUTSIDE://:9092
      KAFKA_INTER_BROKER_LISTENER_NAME: INSIDE
      KAFKA_ADVERTISED_LISTENERS: INSIDE://kafka:29092,OUTSIDE://kafka:9092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: INSIDE:PLAINTEXT,OUTSIDE:PLAINTEXT
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_LOG_DIRS: /kafka/kafka-logs # Sets the directory where Kafka will store log files
      KAFKA_BROKER_ID: 1 # Assigns a unique identifier to the Kafka broker
    # Mapping Docker socket and Kafka logs directory for Kafka data persistence
    volumes:
    - /var/run/docker.sock:/var/run/docker.sock # Allows the container to communicate with the Docker daemon
    - /home/acit3855zaaf/kafka:/kafka/kafka-logs # Persists Kafka logs across container restarts
    depends_on:
    - "zookeeper"

  db:
    hostname: db
    image: mysql:5.7
    container_name: db
    environment:
      MYSQL_DATABASE: events
      MYSQL_USER: user
      MYSQL_PASSWORD: natasha25
      MYSQL_ROOT_PASSWORD: natasha25
    ports:
      - '3306:3306'
    expose:
      - '3306'
    volumes:
      - my-db:/var/lib/mysql

  receiver:
    build:
     context: ../receiver
     dockerfile: Dockerfile
    container_name: "receiver"
    environment:
      - TARGET_ENV=test
    volumes:
      - /home/acit3855zaaf/config/receiver:/config
      - /home/acit3855zaaf/logs:/logs
    restart: always
    ports:
      - "8080"
    depends_on:
      - kafka
    networks:
      - api.network

  storage:
    build:
     context: ../storage
     dockerfile: Dockerfile
    container_name: "storage"
    environment:
      - TARGET_ENV=test
    volumes:
      - /home/acit3855zaaf/config/storage:/config
      - /home/acit3855zaaf/logs:/logs
    restart: always
    ports:
      - "8090"
    depends_on:
      - kafka
      - db
    networks:
      - api.network

  processing:
    build:
     context: ../processing
     dockerfile: Dockerfile
    container_name: "processing"
    environment:
      - TARGET_ENV=test
    volumes:
      - /home/acit3855zaaf/config/processing:/config
      - /home/acit3855zaaf/logs:/logs
      - processing-db:/data
    restart: always
    ports:
      - "8100"
    depends_on:
      - storage
    networks:
      - api.network

  audit_log:
    build:
     context: ../audit_log
     dockerfile: Dockerfile
    container_name: "audit_log"
    environment:
      - TARGET_ENV=test
    volumes:
      - /home/acit3855zaaf/config/audit_log:/config
      - /home/acit3855zaaf/logs:/logs
    restart: always
    ports:
      - "8110"
    depends_on:
      - kafka
    networks:
      - api.network

  dashboard-ui:
    build:
      context: ../dashboard-ui
      dockerfile: Dockerfile
    container_name: "dashboard-ui"
    image: dashboard
    restart: always
    ports:
      - "3000"
    depends_on:
      - processing
      - audit
    networks:
      - api.network

  nginx:
    image: nginx:latest
    # Connects the conf file of the container to the conf file in our folder
    volumes:
      - /home/acit3855zaaf/nginx/nginx.conf:/etc/nginx/nginx.conf:ro
    # It will start up the nginx only when all api containers have started
    depends_on:
      - "receiver"
      - "storage"
      - "processing"
      - "audit_log"
      - "dashboard-ui"
    # Connects the port 80 of the nginx container to localhost:80 or localhost
    ports:
      - "80:80"
    networks:
      - "api.network"


volumes:
  my-db:
  processing-db:

networks:
  api.network:
